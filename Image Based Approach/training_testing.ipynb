{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Frame Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T23:05:26.295924Z",
     "iopub.status.busy": "2023-01-20T23:05:26.295411Z",
     "iopub.status.idle": "2023-01-20T23:05:26.313520Z",
     "shell.execute_reply": "2023-01-20T23:05:26.312808Z",
     "shell.execute_reply.started": "2023-01-20T23:05:26.295891Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import cv2\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, log_loss\n",
    "\n",
    "\n",
    "# #%% [code]\n",
    "class VideoIterator(Dataset):\n",
    "    def __init__(self, df, transforms, device, aug=False):\n",
    "        self.df = df\n",
    "        print(self.df[\"stalled\"].value_counts())\n",
    "        self.transforms = transforms\n",
    "        self.device = device\n",
    "        self.aug = aug\n",
    "        self.rotations = [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
    "        self.flips = [0, 1, -1]\n",
    "        \n",
    "    def _frame_number(self, image_path):\n",
    "        \"\"\" Extracts frame number from filepath \"\"\"\n",
    "        image_path = image_path.replace('\\\\','/')\n",
    "        try:\n",
    "            return int(image_path.split('/')[-1].split('.jpg')[0])\n",
    "        except:\n",
    "            print(\"Got error while getting image number ....\")\n",
    "            exit()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        x = []\n",
    "        x_back=[]\n",
    "        #print(row[\"path\"])\n",
    "        dir_path = row[\"path\"].split('.mp4')[0]\n",
    "\n",
    "\n",
    "        all_img_path = sorted(glob.glob(f'{dir_path}/*.jpg'), key=lambda path: self._frame_number(path))\n",
    "        all_img_path_back = sorted(glob.glob(f'{dir_path}/*.jpg'), key=lambda path: self._frame_number(path), reverse=True)\n",
    "\n",
    "        \n",
    "#         video = cv2.VideoCapture(row[\"path\"])\n",
    "#         if not video.isOpened():\n",
    "#             print(\"Error opening video file.\")\n",
    "        for for_img, back_img in zip(all_img_path, all_img_path_back):\n",
    "        #for for_img in all_img_path:\n",
    "            frame1 = cv2.imread(for_img)\n",
    "            #frame1 = cv2.resize(frame1, (112,112), interpolation=cv2.INTER_CUBIC)\n",
    "            frame2 = cv2.imread(back_img)\n",
    "            #frame2 = cv2.resize(frame2, (112,112), interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            x.append(frame1)\n",
    "            x_back.append(frame2)\n",
    "        #video.release()\n",
    "        \n",
    "        if self.aug:    \n",
    "            if random.random() <= 0.25:\n",
    "                rot = random.choice(self.rotations)\n",
    "                x = [cv2.rotate(img, rot) for img in x]\n",
    "                x_back = [cv2.rotate(img, rot) for img in x_back]\n",
    "            if random.random() <= 0.25:\n",
    "                fl = random.choice(self.flips)\n",
    "                x = [cv2.flip(img, fl) for img in x]\n",
    "                x_back = [cv2.flip(img, fl) for img in x_back]\n",
    "        \n",
    "        x = [self.transforms(frame) for frame in x]\n",
    "        x_back = [self.transforms(frame) for frame in x_back]\n",
    "        \n",
    "        # print(type(x))\n",
    "        #print(x)\n",
    "        # print(f'shape of x {x.shape}')\n",
    "        x = torch.stack(x)\n",
    "        x_back = torch.stack(x_back)\n",
    "        #print(\"\\n\\n\\n first size \", x.size(), \"\\n\\n\\n\\n\")\n",
    "        x = x.permute(1, 0, 2, 3) #Buji nai \n",
    "        x_back = x_back.permute(1, 0, 2, 3) #Buji nai \n",
    "        #print(\"\\n\\n\\n second size \", x.size(), \"\\n\\n\\n\\n\")\n",
    "        x = x.unsqueeze(0)\n",
    "        x_back = x_back.unsqueeze(0)\n",
    "        #print(\"\\n\\n\\n third size \", x.size(), \"\\n\\n\\n\\n\")\n",
    "        x = x.to(self.device, dtype=torch.float)\n",
    "        #print(\"\\n\\n\\n\\n X size \", x.size(), \"\\n\\n\")\n",
    "        x_back = x_back.to(self.device, dtype=torch.float)\n",
    "        #print(\"\\n\\n\\n\\n x_back size \", x_back.size(), \"\\n\\n\")\n",
    "        y = torch.FloatTensor([[row[\"stalled\"]]]).to(self.device)\n",
    "        f_name = row[\"path\"].split('/')[-1]\n",
    "        #print(\"Image dataloader name : \", f_name, '\\n')\n",
    "        return x, x_back, y #, f_name\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# img model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T23:07:13.473462Z",
     "iopub.status.busy": "2023-01-20T23:07:13.472635Z",
     "iopub.status.idle": "2023-01-20T23:07:13.480220Z",
     "shell.execute_reply": "2023-01-20T23:07:13.479443Z",
     "shell.execute_reply.started": "2023-01-20T23:07:13.473421Z"
    }
   },
   "outputs": [],
   "source": [
    "class R2plus1dModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2plus1dModel, self).__init__()\n",
    "\n",
    "        cnn = torchvision.models.video.r2plus1d_18(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(cnn.children())[:-1])\n",
    "        self.fc = nn.Linear(in_features=1024,\n",
    "                                out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        x = self.cnn(input1)\n",
    "        x_back = self.cnn(input2)\n",
    "        \n",
    "#         print(x.size())\n",
    "#         print(x_back.size())\n",
    "        \n",
    "        x = torch.cat((x, x_back), 1).squeeze().unsqueeze(0)\n",
    "        x = self.fc(x)\n",
    "        x = self.sig(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training + Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-20T23:43:08.459281Z",
     "iopub.status.busy": "2023-01-20T23:43:08.458852Z",
     "iopub.status.idle": "2023-01-20T23:44:46.600733Z",
     "shell.execute_reply": "2023-01-20T23:44:46.599037Z",
     "shell.execute_reply.started": "2023-01-20T23:43:08.459248Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # #%% [code]\n",
    "# # import os\n",
    "# # import cv2\n",
    "# # import math\n",
    "# # import time\n",
    "# # import random\n",
    "# # import pandas as pd\n",
    "# # import numpy as np\n",
    "\n",
    "# # import torch\n",
    "# # import torchvision\n",
    "# # import torch.nn as nn\n",
    "# # from torch.utils.data.dataset import Dataset\n",
    "# # from torchvision.transforms import transforms\n",
    "# # from torch.optim.lr_scheduler import OneCycleLR\n",
    "# # #from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# # from sklearn.metrics import matthews_corrcoef, accuracy_score, log_loss\n",
    "\n",
    "\n",
    "# # #%% [code]\n",
    "# # class VideoIterator(Dataset):\n",
    "# #     def __init__(self, df, transforms, device, aug=False):\n",
    "# #         self.df = df\n",
    "# #         print(self.df[\"stalled\"].value_counts())\n",
    "# #         self.transforms = transforms\n",
    "# #         self.device = device\n",
    "# #         self.aug = aug\n",
    "# #         self.rotations = [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
    "# #         self.flips = [0, 1, -1]\n",
    "        \n",
    "# #     def __getitem__(self, index):\n",
    "# #         row = self.df.iloc[index]\n",
    "# #         x = []\n",
    "# #         #print(row[\"path\"])\n",
    "# #         video = cv2.VideoCapture(row[\"path\"])\n",
    "# #         if not video.isOpened():\n",
    "# #             print(\"Error opening video file.\")\n",
    "# #         while video.isOpened():\n",
    "# #             ret, frame = video.read()\n",
    "# #             if ret:\n",
    "# #                 x.append(frame)\n",
    "# #                 #print(f' return {ret}')\n",
    "# #             else:\n",
    "# #                 #print(f' return {ret}')\n",
    "# #                 break\n",
    "# #         video.release()\n",
    "        \n",
    "# #         if self.aug:    \n",
    "# #             if random.random() <= 0.25:\n",
    "# #                 rot = random.choice(self.rotations)\n",
    "# #                 x = [cv2.rotate(img, rot) for img in x]\n",
    "# #             if random.random() <= 0.25:\n",
    "# #                 fl = random.choice(self.flips)\n",
    "# #                 x = [cv2.flip(img, fl) for img in x]\n",
    "        \n",
    "# #         x = [self.transforms(frame) for frame in x]\n",
    "# #         # print(type(x))\n",
    "# #         #print(x)\n",
    "# #         # print(f'shape of x {x.shape}')\n",
    "# #         x = torch.stack(x)\n",
    "# #         #print(\"\\n\\n\\n first size \", x.size(), \"\\n\\n\\n\\n\")\n",
    "# #         x = x.permute(1, 0, 2, 3) #Buji nai \n",
    "# #         #print(\"\\n\\n\\n second size \", x.size(), \"\\n\\n\\n\\n\")\n",
    "# #         x = x.unsqueeze(0)\n",
    "# #         #print(\"\\n\\n\\n third size \", x.size(), \"\\n\\n\\n\\n\")\n",
    "# #         x = x.to(self.device, dtype=torch.float)\n",
    "# #         y = torch.FloatTensor([[row[\"stalled\"]]]).to(self.device)\n",
    "# #         return x, y\n",
    "\n",
    "# #     def __len__(self):\n",
    "# #         return len(self.df)\n",
    "\n",
    "# #     def shuffle(self):\n",
    "# #         self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# # #%% [code]\n",
    "# class R2plus1dModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(R2plus1dModel, self).__init__()\n",
    "\n",
    "#         self.cnn = torchvision.models.video.r2plus1d_18(pretrained=True)\n",
    "#         self.cnn.fc = nn.Linear(in_features=512,\n",
    "#                                 out_features=1)\n",
    "#         self.sig = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         x = self.cnn(input)\n",
    "#         #x = self.sig(x)\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# # class Rmc3Model(nn.Module):\n",
    "# #     def __init__(self):\n",
    "# #         super(Rmc3Model, self).__init__()\n",
    "\n",
    "# #         self.cnn = torchvision.models.video.mc3_18(pretrained=True)\n",
    "# #         self.cnn.fc = nn.Linear(in_features=512,\n",
    "# #                                 out_features=1)\n",
    "# #         self.sig = nn.Sigmoid()\n",
    "\n",
    "# #     def forward(self, input):\n",
    "# #         x = self.cnn(input)\n",
    "# #         x = self.sig(x)\n",
    "# #         return x\n",
    "\n",
    "\n",
    "# # class R3dModel(nn.Module):\n",
    "# #     def __init__(self):\n",
    "# #         super(R3dModel, self).__init__()\n",
    "\n",
    "# #         self.cnn = torchvision.models.video.r3d_18(pretrained=True)\n",
    "# #         self.cnn.fc = nn.Linear(in_features=512,\n",
    "# #                                 out_features=1)\n",
    "# #         self.sig = nn.Sigmoid()\n",
    "\n",
    "# #     def forward(self, input):\n",
    "# #         x = self.cnn(input)\n",
    "# #         x = self.sig(x)\n",
    "# #         return x\n",
    "\n",
    "\n",
    "# #%% [code]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "#%% [code]\n",
    "data_folder = \"/kaggle/input/alzheimer-otsu/nano_voxel_midsampling_otsu\"\n",
    "train_data_folder = data_folder + \"/\"\n",
    "train_csv = data_folder + \"train_data.csv\"\n",
    "\n",
    "\n",
    "#%% [code]\n",
    "transformations = transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989])\n",
    "])\n",
    "    \n",
    "# df = pd.read_csv(train_csv)\n",
    "# df[\"path\"] = train_data_folder + df[\"filename\"]\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/weight-files-valid-test-set/train_0.csv') \n",
    "train_df[\"path\"] = train_data_folder + train_df[\"filename\"] \n",
    "train_df['stalled'] = train_df['class']\n",
    "train_df.drop(['class'], axis=1) \n",
    "\n",
    "val_df = pd.read_csv('../input/weight-files-valid-test-set/fold_2_validation.csv') \n",
    "val_df[\"path\"] = train_data_folder + val_df[\"filename\"]\n",
    "val_df['stalled'] = val_df['class']\n",
    "val_df.drop(['class'], axis=1) \n",
    "\n",
    "# train_df, val_df = train_test_split(df, \n",
    "#                                     test_size=0.1, \n",
    "#                                     shuffle=True, \n",
    "#                                     stratify=df[\"stalled\"].values, \n",
    "#                                     random_state=42)\n",
    "\n",
    "print(\"Training data\")\n",
    "train_data_iterator = VideoIterator(train_df, transformations, device, True)\n",
    "print(\"\\nValidation data\")\n",
    "val_data_iterator = VideoIterator(val_df, transformations, device, False)\n",
    "\n",
    "w = len(train_df[train_df[\"stalled\"] == 0]) / len(train_df[train_df[\"stalled\"] == 1])\n",
    "print(\"\\nStalled class weight: \" + str(w))\n",
    "\n",
    "\n",
    "#%% [code]\n",
    "\n",
    "model_folder = \"./models/model_v1/\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "# os.makedirs(model_folder)\n",
    "\n",
    "no_epochs = 30\n",
    "log_interval = 20\n",
    "\n",
    "# Choose model architecture here:\n",
    "# model = R3dModel().to(device)\n",
    "# model = Rmc3Model().to(device)\n",
    "model = Encoder().to(device)\n",
    "\n",
    "# model_path = './best.pth'\n",
    "# model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(device) #torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# this is actually cosine annealing\n",
    "lr_scheduler = OneCycleLR(optimizer, pct_start=0.0001, max_lr=1e-4, epochs=no_epochs, steps_per_epoch=len(train_data_iterator))\n",
    "\n",
    "#summary_writer = SummaryWriter(model_folder + \"tensorlogs/\")\n",
    "\n",
    "\n",
    "#%% [code]\n",
    "best_mcc = -1\n",
    "best_loss = math.inf\n",
    "\n",
    "if os.path.exists('./log.txt'):\n",
    "    log_f = open('./log.txt', 'a')\n",
    "else:\n",
    "    log_f = open('./log.txt', 'w')\n",
    "\n",
    "accumulation_steps = 32    \n",
    "\n",
    "for i in range(no_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    partial_loss_sum = 0\n",
    "    print(\"\\nEpoch \" + str(i))\n",
    "    start_time = time.time()\n",
    "    train_data_iterator.shuffle()\n",
    "    train_losses = []\n",
    "    for j, (x,x_back, y) in enumerate(train_data_iterator):\n",
    "        outputs = model(x, x_back)\n",
    "        loss = criterion(outputs, y)\n",
    "        outputs = torch.nn.Sigmoid()(outputs)\n",
    "        #optimizer.zero_grad()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        partial_loss_sum += loss.item()\n",
    "        if y[0].item() == 1:\n",
    "            loss = loss * w\n",
    "        loss.backward()\n",
    "        if (j+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Empty cache\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        if (j + 1) % log_interval == 0:\n",
    "            end_time = time.time()\n",
    "            total_time = round(end_time - start_time, 2)\n",
    "            partial_loss = round(partial_loss_sum / log_interval, 6)\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            print(\"    \" + str(j + 1) + \"/\" + str(len(train_data_iterator)) + \" | loss \" + str(partial_loss) + \" | lr \" + str(lr) + \" | \" + str(total_time) + \"s\")\n",
    "            start_time = time.time()\n",
    "            partial_loss_sum = 0\n",
    "    train_loss = round(sum(train_losses) / len(train_losses), 4)\n",
    "                    \n",
    "    print(\"\\nEvaluating...\")\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_p = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for j, (x,x_back, y) in enumerate(val_data_iterator):\n",
    "            outputs = model(x, x_back)\n",
    "            p = outputs[0].item()\n",
    "            y_pred_p.append(p)\n",
    "            if p < 0.5:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = 1\n",
    "            y_pred.append(p)\n",
    "            y_true.append(y[0].item())\n",
    "\n",
    "    val_mcc = round(matthews_corrcoef(y_true, y_pred), 4)\n",
    "    val_acc = round(accuracy_score(y_true, y_pred), 4)\n",
    "    val_loss = round(log_loss(y_true, y_pred_p), 4)\n",
    "\n",
    "    if val_mcc >= best_mcc or val_loss <= best_loss: \n",
    "        model_path = model_folder + \"model_epoch:\" + str(i) + \"_mcc:\" + str(val_mcc) + \"_acc:\" + str(val_acc) + \"_loss\" + str(val_loss) + \".pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        if val_mcc >= best_mcc:\n",
    "            best_mcc = val_mcc\n",
    "        if val_loss <= best_loss:\n",
    "            best_loss = val_loss\n",
    "\n",
    "    print(\"Train loss: \" + str(train_loss))\n",
    "    print(\"Val loss: \" + str(val_loss))\n",
    "    print(\"Val MCC: \" + str(val_mcc))\n",
    "    print(\"Val accuracy: \" + str(val_acc))  \n",
    "    print(\"Train loss: \" + str(train_loss),\"Val loss: \" + str(val_loss),\"Val MCC: \" + str(val_mcc),\"Val accuracy: \" + str(val_acc), \"\\n\", file=log_f)  \n",
    "log_f.close()\n",
    "    # summary_writer.add_scalar(\"train_loss\", train_loss, i)\n",
    "    # summary_writer.add_scalar(\"val_loss\", val_loss, i)\n",
    "    # summary_writer.add_scalars(\"loss\", {\"train\": train_loss, \"val\": val_loss}, i)\n",
    "    # summary_writer.add_scalar(\"val_acc\", val_acc, i)\n",
    "    # summary_writer.add_scalar(\"val_mcc\", val_mcc, i)\n",
    "    # summary_writer.add_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989])\n",
    "])\n",
    "\n",
    "data_folder = \"../input/alzheimer-nano-orange-blue/nano_orangeblue_resized_all\"\n",
    "test_data_folder = data_folder + \"/\"\n",
    "\n",
    "test_df = pd.read_csv('../input/weight-files-valid-test-set/fold_2_testing.csv') \n",
    "test_df[\"path\"] = test_data_folder + test_df[\"filename\"] \n",
    "test_df['stalled'] = test_df['class']\n",
    "\n",
    "\n",
    "data_iterator = VideoIterator(test_df, transformations, device)\n",
    "print(len(data_iterator))\n",
    "\n",
    "model = R2plus1dModel().to(device)\n",
    "#model = Rmc3Model().to(device)\n",
    "#model = R3dModel().to(device)\n",
    "\n",
    "model_path = '../input/weight-files-valid-test-set/Without Bi-Directional (OrangeBlue)/log_R3d/model_epoch 25_mcc 0.8585_acc 0.9292_loss0.255.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.train()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "filenames = []\n",
    "#with torch.no_grad():\n",
    "for j, (_,x, y, f_name) in enumerate(data_iterator):\n",
    "    #x = Variable(x, requires_grad=True)\n",
    "    if j % 20 == 0:\n",
    "        print(j)\n",
    "    outputs = model(x)\n",
    "    p = outputs[0].item()\n",
    "    y_pred.append(p)\n",
    "    y_true.append(y[0].item())\n",
    "    filenames.append(f_name)\n",
    "        \n",
    "y_pred  = [0 if i<0.5 else 1 for i in y_pred]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=[]\n",
    "fp=[]\n",
    "fn=[]\n",
    "for i, each in enumerate(y_pred):\n",
    "    if each == 1 and y_true[i] == each:\n",
    "        tp.append(i)\n",
    "    elif each==1 and y_true[i] != each:\n",
    "        fp.append(i)\n",
    "    elif each==0 and y_true[i] == 1:\n",
    "        fn.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./all_files.csv')\n",
    "fnames = df['filename'].values\n",
    "\n",
    "print(fnames[fn])\n",
    "\n",
    "#tp_df = pd.DataFrame({'True Positive Train':fnames[tp]})\n",
    "#fp_df = pd.DataFrame({'False Positive All': fnames[fp]})\n",
    "fn_df = pd.DataFrame({'False Negative All': fnames[fn]})\n",
    "\n",
    "#tp_df.to_csv('True Positive Train.csv', index=False)\n",
    "fn_df.to_csv('False Negative All files R3d.csv', index=False)\n",
    "#fn_df.to_csv('False Negative Train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, log_loss, recall_score\n",
    "\n",
    "val_mcc = round(matthews_corrcoef(y_true, y_pred), 4)\n",
    "val_acc = round(accuracy_score(y_true, y_pred), 4)\n",
    "#sensitivity = round(recall_score(y_true , lf_pred), 4)\n",
    "#specificity = round(recall_score(np.logical_not(y_true) , np.logical_not(lf_pred)), 4)\n",
    "\n",
    "print(\"Test/Validation MCC =  \", val_mcc)\n",
    "print(\"Test/Validation Acc =  \", val_acc)\n",
    "#print(\"Test/Validation Sensitivity =  \", sensitivity)\n",
    "#print(\"Test/Validation specificity =  \", specificity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
