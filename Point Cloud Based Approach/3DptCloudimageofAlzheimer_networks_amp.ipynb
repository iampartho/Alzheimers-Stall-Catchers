{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "3DptCloudimageofAlzheimer_networks_amp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjL-RPvWl6zQ",
        "colab_type": "text"
      },
      "source": [
        "# Test GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7eGOe9mJkE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cded0d80-f526-4e0b-90ba-20eb8c4a1be5"
      },
      "source": [
        "import torch\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG067iUUQPeR",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok8yK4RbDFNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dd4ca918-58f0-437b-c505-312a90f45760"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9uz1q_pllbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Folder => \"Alzheimer Competition\"\n",
        "https://drive.google.com/drive/folders/1-NIobsSrpU5JyUfu0bqbuWZU32GVZ7-m?usp=sharing\n",
        "\n",
        "Folder => \"SayeedColab\"\n",
        "https://drive.google.com/drive/folders/1wnL3y-kltnGwsV9dhha6BbOI7UwF0YJW?usp=sharing\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Uh_vIJQZzs",
        "colab_type": "text"
      },
      "source": [
        "# Copy Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWwCqwra84SR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f7caeba-5006-4185-8dab-84c0dd7cdb71"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "#shutil.copyfile(\"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/ranger.py\", \"ranger.py\")\n",
        "shutil.copyfile(\"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/resnext.py\", \"resnext.py\")\n",
        "#shutil.copyfile(\"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/resnet.py\", \"resnet.py\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/traintestlist.zip\";\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAOia2rODiZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "56ecc8da-86b0-4e32-b707-f1864d453860"
      },
      "source": [
        "!jar -xf \"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/Alzheimer Data/micro_1.zip\";\n",
        "print(\"partition 1 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/Alzheimer Data/micro_2.zip\";\n",
        "print(\"partition 2 imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/Alzheimer Data/micro_3.zip\";\n",
        "print(\"partition 3 imported\")\n",
        "\n",
        "files = [f for f in glob.glob(\"micro/\" + \"*\" + \".pt\", recursive=True)]\n",
        "print(\"Total: \" + str(len(files)) + \" should be 2399\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "partition 1 imported\n",
            "partition 2 imported\n",
            "partition 3 imported\n",
            "Total: 2399 should be 2399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ofABr9VByi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NEW DATA\n",
        "\"\"\"\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/stall.zip\";\n",
        "print(\"new data stall imported\")\n",
        "\n",
        "!jar -xf \"/content/drive/My Drive/SayeedColab/Alzheimer Data/nonstall_0.zip\";\n",
        "print(\"new data nonstall_0 imported\")\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDPeoCa-e5GP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -rf loss_acc_curve # remove any folder fully"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWfvjBHvQLLb",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqOgAV40C5DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from sklearn.metrics import matthews_corrcoef as mcc\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "#from torchvision.models.video import r3d_18\n",
        "\n",
        "torch.manual_seed(100)\n",
        "np.random.seed(0)\n",
        "\n",
        "import csv\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEau83HIC5Dj",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWjtb3jFxUli",
        "colab_type": "text"
      },
      "source": [
        "### Balanced Batch Sampler\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQFDF7F5l2CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch.utils.data\n",
        "import random\n",
        "\n",
        "\n",
        "class BalancedBatchSampler(torch.utils.data.sampler.Sampler):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = {}\n",
        "        self.balanced_max = 0\n",
        "        # Save all the indices for all the classes\n",
        "        for idx in range(0, len(dataset)):\n",
        "            label = self._get_label(dataset, idx)\n",
        "            if label not in self.dataset:\n",
        "                self.dataset[label] = []\n",
        "            self.dataset[label].append(idx)\n",
        "            self.balanced_max = len(self.dataset[label]) \\\n",
        "                if len(self.dataset[label]) > self.balanced_max else self.balanced_max\n",
        "        \n",
        "        # Oversample the classes with fewer elements than the max\n",
        "        for label in self.dataset:\n",
        "            while len(self.dataset[label]) < self.balanced_max:\n",
        "                self.dataset[label].append(random.choice(self.dataset[label]))\n",
        "    \n",
        "        self.keys = list(self.dataset.keys())\n",
        "        self.currentkey = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        while len(self.dataset[self.keys[self.currentkey]]) > 0:\n",
        "            yield self.dataset[self.keys[self.currentkey]].pop()\n",
        "            self.currentkey = (self.currentkey + 1) % len(self.keys)\n",
        "\n",
        "    \n",
        "    def _get_label(self, dataset, idx):\n",
        "        dataset_type = type(dataset)\n",
        "        if dataset_type is torchvision.datasets.MNIST:\n",
        "            return dataset.train_labels[idx].item()\n",
        "        elif dataset_type is torchvision.datasets.ImageFolder:\n",
        "            return dataset.imgs[idx][1]\n",
        "        else:\n",
        "            (image_sequence, target) = dataset.__getitem__(idx)\n",
        "            return target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.balanced_max*len(self.keys)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8c05JU4xmkQ",
        "colab_type": "text"
      },
      "source": [
        "### Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmJqzMzjp3qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class VoxelDataset(Dataset):\n",
        "    def __init__(self, dataset_path, split_path, split_number, training):\n",
        "        self.training = training\n",
        "        self.sequences, self.labels = self._extract_sequence_paths_and_labels(dataset_path, split_path, split_number,\n",
        "                                                                              training)  # creating a list of directories where the extracted frames are saved\n",
        "        self.label_names = [\"Non-stalled\", \"Stalled\"]  # Getting the label names or name of the class\n",
        "        self.num_classes = len(self.label_names)  # Getting the number of class\n",
        "\n",
        "\n",
        "    def _extract_sequence_paths_and_labels(\n",
        "            self, dataset_path, split_path=\"data/traintestlist\", split_number=0, training=True\n",
        "    ):\n",
        "        \"\"\" Extracts paths to sequences given the specified train / test split \"\"\"\n",
        "        fn = f\"fold_{split_number}_train.csv\" if training else f\"fold_{split_number}_test.csv\"\n",
        "        split_path = os.path.join(split_path, fn)\n",
        "        df = pd.read_csv(split_path)\n",
        "        file_name = df['filename'].values\n",
        "        all_labels = df['class'].values\n",
        "        sequence_paths = []\n",
        "        classes = []\n",
        "        for i, video_name in enumerate(file_name):\n",
        "            seq_name = video_name.split(\".mp4\")[0]\n",
        "            sequence_paths += [os.path.join(dataset_path, seq_name).replace('\\\\', '/')]\n",
        "            classes += [all_labels[i]]\n",
        "        return sequence_paths, classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence_path = self.sequences[index % len(self)]\n",
        "        target = self.labels[index % len(self)]\n",
        "\n",
        "        X = torch.load(sequence_path + \".pt\")\n",
        "\n",
        "        return X, target\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMEDRVRQxshP",
        "colab_type": "text"
      },
      "source": [
        "### Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMP7nk43xKJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "56fa4137-3037-4427-f3e4-0d5195210f75"
      },
      "source": [
        "batch_size = 86\n",
        "\n",
        "split_number = 0\n",
        "\n",
        "augmentation_enabled = True\n",
        "#augment_volume = 16\n",
        "augment_volume = 1\n",
        "IS_FIRST_STAGE = False\n",
        "\n",
        "if augmentation_enabled ==  True:\n",
        "  batch_size = int(batch_size/augment_volume)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "dataset_path = 'micro'\n",
        "split_path = 'traintestlist'\n",
        "\n",
        "depth, height, width = 32, 64, 64\n",
        "\n",
        "# Define training set\n",
        "\n",
        "train_dataset_vox = VoxelDataset(\n",
        "    dataset_path=dataset_path,\n",
        "    split_path=split_path,\n",
        "    split_number=split_number,\n",
        "    training=True,\n",
        ")\n",
        "\n",
        "##use balancebatch in first stage \n",
        "if IS_FIRST_STAGE:\n",
        "  train_dataloader_vox = DataLoader(train_dataset_vox, batch_size= batch_size,sampler=BalancedBatchSampler(train_dataset_vox),shuffle=False, num_workers=4)\n",
        "else:\n",
        "  train_dataloader_vox = DataLoader(train_dataset_vox, batch_size= batch_size,shuffle=True, num_workers=4)\n",
        "\n",
        "train_dataloader_vox = DataLoader(train_dataset_vox, batch_size= batch_size,shuffle=True, num_workers=4)\n",
        "# Define test set\n",
        "test_dataset_vox = VoxelDataset(\n",
        "    dataset_path=dataset_path,\n",
        "    split_path=split_path,\n",
        "    split_number=split_number,\n",
        "    training=False,\n",
        ")\n",
        "test_dataloader_vox = DataLoader(test_dataset_vox, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "endtime = time.time()\n",
        "\n",
        "print(\"Elapsed time : \" + str(endtime-start))\n",
        "\n",
        "gc.collect() \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time : 0.01900506019592285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecG1PyL6BMrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16f2c9f1-a6f6-4ac2-aa88-84903fdcd07c"
      },
      "source": [
        "len(train_dataloader_vox)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSzI-gKJC5D2",
        "colab_type": "text"
      },
      "source": [
        "# Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_n_kiriRFa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shutil.copyfile(\"/content/drive/My Drive/Alzheimer Competition/lr1e-4_dec8e-4_90.484_mcc_0.766.pth\", \"weight_3D.pth\")\n",
        "shutil.copyfile(\"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/kinetics_resnext_101_RGB_16_best.pth\", \"weight_3D.pth\")\n",
        "checkpoint_model = \"weight_3D.pth\"\n",
        "\n",
        "shutil.copyfile(\"/content/drive/My Drive/AlzheimerStallCatcher3DConvPointCloud/3D_ptcl2stage_resnext101_11for_cloud_size_32_64_64_acc_80.2_mcc_0.588.pth\", \"weight_3D1.pth\")\n",
        "checkpoint_model1 = \"weight_3D1.pth\"\n",
        "\n",
        "# fold3_resnet101_aug16_32_64_64_acc_85.476_mcc_0.641.pth\n",
        "# lr1e-4_dec1e-3_acc_89.649_mcc_0.744.pth\n",
        "# lr1e-4_dec8e-4_90.484_mcc_0.766.pth"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI0IKKUVP_22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import resnext\n",
        "#import resnet\n",
        "class Encoder_pt(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Encoder_pt, self).__init__()\n",
        "        '''\n",
        "        rsnxt = resnet.resnet101(\n",
        "                num_classes=600,\n",
        "                shortcut_type='B',\n",
        "                sample_size=64,\n",
        "                sample_duration=32)\n",
        "        '''\n",
        "        rsnxt = resnext.resnext101(\n",
        "                num_classes=600,\n",
        "                shortcut_type='B',\n",
        "                cardinality=32,\n",
        "                sample_size=64,\n",
        "                sample_duration=32)\n",
        "\n",
        "        \n",
        "        ##pretrained weight loading\n",
        "        rsnxt = rsnxt.cuda()\n",
        "        rsnxt = nn.DataParallel(rsnxt, device_ids=None)\n",
        "        pretrain = torch.load(checkpoint_model, map_location=torch.device('cpu'))\n",
        "        rsnxt.load_state_dict(pretrain['state_dict'])\n",
        "        \n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.15)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "        self.feature_extractor = nn.Sequential(*list(rsnxt.module.children())[0:2])\n",
        "        self.feature_extractor_new1 = nn.Sequential(*list(rsnxt.module.children())[2:3])\n",
        "        self.feature_extractor_new2 = nn.Sequential(*list(rsnxt.module.children())[3:4])\n",
        "        self.feature_extractor_new3 = nn.Sequential(*list(rsnxt.module.children())[4:5])\n",
        "        self.feature_extractor_new4 = nn.Sequential(*list(rsnxt.module.children())[5:6])\n",
        "        self.feature_extractor_new5 = nn.Sequential(*list(rsnxt.module.children())[6:7])\n",
        "        self.feature_extractor_new6 = nn.Sequential(*list(rsnxt.module.children())[7:8])\n",
        "        self.feature_extractor_new7 = nn.Sequential(*list(rsnxt.module.children())[8:9])\n",
        "        #self.feature_extractor_new8 = nn.Sequential(*list(resnet.children())[9:10])\n",
        "        self.feature_extractor_new8 = nn.Linear(rsnxt.module.fc.in_features, num_classes)\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #with torch.no_grad():\n",
        "        x = self.feature_extractor(x)     ##more droputs added\n",
        "        x = self.dropout1(x)  \n",
        "        x = self.feature_extractor_new1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.feature_extractor_new2(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.feature_extractor_new3(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.feature_extractor_new4(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.feature_extractor_new5(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.feature_extractor_new6(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.feature_extractor_new7(x)\n",
        "        x = x.view(x.shape[0],-1)   #without flattening it can't be passed through dense layer\n",
        "        x = self.dropout2(x)\n",
        "        x = self.feature_extractor_new8(x)\n",
        "        x = self.softmax(x)\n",
        "        #x = x.view(x.size(0), -1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYX01U05N2c4",
        "colab_type": "text"
      },
      "source": [
        "# **Installing Apex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ARg-z1_NvAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  import apex\n",
        "except Exception:\n",
        "  ! git clone https://github.com/NVIDIA/apex.git\n",
        "  % cd apex\n",
        "  !pip install --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n",
        "  %cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xjg5iMiGbbW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05a659e9-8bf9-4976-9cbf-9376f0133da9"
      },
      "source": [
        "from apex import amp\n",
        "\n",
        "######################################################################################\n",
        "## Enable this parameter by setting True if you resume training from pretrained weight\n",
        "######################################################################################\n",
        "RESUME_TRAINING = True\n",
        "\n",
        "use_amp = True    #Using automatic mixed precision\n",
        "\n",
        "model = Encoder_pt(\n",
        "    num_classes=2,\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "### Optimizer ####\n",
        "if RESUME_TRAINING:\n",
        "  learning_rate = 2e-4\n",
        "  wd = 6e-4\n",
        "else:\n",
        "  learning_rate = 5e-4\n",
        "  wd = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay= wd)  #added L2 regularization\n",
        "\n",
        "\n",
        "opt_level = \"O2\"\n",
        "\n",
        "##For first stage\n",
        "if IS_FIRST_STAGE:\n",
        "  if use_amp:\n",
        "    model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
        "\n",
        "##For 2nd stage\n",
        "if RESUME_TRAINING:\n",
        "  if use_amp:\n",
        "    checkpoint = torch.load(checkpoint_model1)  ##checkpoint_model1 is the pretrained load in first stage\n",
        "    model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    amp.load_state_dict(checkpoint['amp'])\n",
        "  \n",
        "  else:\n",
        "    #File name of previously trained weight file\n",
        "    #checkpoint_model1=\"model_checkpoints/3D_pointcloud_resnet101_0for_cloud_size_32_64_64_acc_32.779_mcc_-0.014.pth\"\n",
        "    checkpoint = torch.load(checkpoint_model1)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    #epoch = checkpoint['epoch']\n",
        "    #loss = checkpoint['loss']\n",
        "\n",
        "#device\n",
        "model"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/resnext.py:129: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder_pt(\n",
              "  (dropout1): Dropout(p=0.15, inplace=False)\n",
              "  (dropout2): Dropout(p=0.4, inplace=False)\n",
              "  (feature_extractor): Sequential(\n",
              "    (0): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
              "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (feature_extractor_new1): Sequential(\n",
              "    (0): ReLU(inplace=True)\n",
              "  )\n",
              "  (feature_extractor_new2): Sequential(\n",
              "    (0): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (feature_extractor_new3): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (feature_extractor_new4): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (feature_extractor_new5): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (8): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (9): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (10): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (11): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (12): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (13): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (14): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (15): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (16): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (17): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (18): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (19): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (20): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (21): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (22): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (feature_extractor_new6): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): ResNeXtBottleneck(\n",
              "        (conv1): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (feature_extractor_new7): Sequential(\n",
              "    (0): AvgPool3d(kernel_size=(2, 2, 2), stride=1, padding=0)\n",
              "  )\n",
              "  (feature_extractor_new8): Linear(in_features=2048, out_features=2, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABT1AYlDdzvd",
        "colab_type": "text"
      },
      "source": [
        "### Model Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuwWzMuOuB6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5216a71d-c9b5-4ad5-e0ce-5901207d707a"
      },
      "source": [
        "#error = nn.BCEWithLogitsLoss().to(device)\n",
        "error = nn.CrossEntropyLoss().to(device)   ## loss function\n",
        "num_epochs = 50\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nif RESUME_TRAINING:\\n  learning_rate = 2e-4\\n  wd = 6e-4\\nelse:\\n  learning_rate = 5e-4\\n  wd = 1e-4\\n\\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay= wd)  #added L2 regularization\\n\\nif RESUME_TRAINING:\\n  optimizer.load_state_dict(checkpoint1['optimizer_state_dict'])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4e-KlLzBza",
        "colab_type": "text"
      },
      "source": [
        "# Visualization and Saving Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNcBjSDXrvbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conf_mat(cf, epoch, acc, mcc, y_true, train_loss, train_acc, test_loss, test_acc):\n",
        "  try:\n",
        "    plt.imshow(cf,cmap=plt.cm.RdYlGn,interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.title('Confusion Matrix without Normalization')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    tick_marks = np.arange(len(set(y_true))) # length of classes\n",
        "    class_labels = ['Non Stalled','Stalled']\n",
        "    tick_marks\n",
        "    plt.xticks(tick_marks,class_labels)\n",
        "    plt.yticks(tick_marks,class_labels)\n",
        "    # plotting text value inside cells\n",
        "    thresh = cf.max() / 2.\n",
        "    for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\n",
        "        plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\n",
        "    #plt.show()\n",
        "    os.makedirs(\"confusion_matrix\", exist_ok=True)\n",
        "    plt.savefig(f\"confusion_matrix/epoch{epoch}_accuracy{round(acc.item(),3)}_mcc_{round(mcc.item(),3)}.png\")\n",
        "    plt.close('all')\n",
        "\n",
        "    os.makedirs(\"loss_acc_curve\", exist_ok=True)\n",
        "\n",
        "    ##creating subplot for loss,acc\n",
        "    fig1, axs = plt.subplots(4,sharex=True,constrained_layout=True)\n",
        "    axs[0].plot(train_loss, color = \"red\") \n",
        "    axs[0].set_title(\"Train loss\")\n",
        "    axs[1].plot(train_acc, color = \"blue\") \n",
        "    axs[1].set_title(\"Train Accuracy\")\n",
        "    axs[2].plot(test_loss, color = \"green\")\n",
        "    axs[2].set_title(\"Test Loss\")\n",
        "    axs[3].plot(test_acc) \n",
        "    axs[3].set_title(\"Test Accuracy\")\n",
        "    #fig1.tight_layout()\n",
        "    #plt.show()\n",
        "    fig1.savefig(f\"loss_acc_curve/epoch{epoch}_accuracy{round(acc.item(),3)}_mcc_{round(mcc.item(),3)}.png\")\n",
        "    plt.close(fig1)\n",
        "  except:\n",
        "    print(\"MCC is 0\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4getcCEuOjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for cross entropy loss\n",
        "def validation(epoch,train_loss, train_acc, test_loss, test_acc):\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  t_loss = 0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for images, labels in test_dataloader_vox:\n",
        "\n",
        "      y_true = np.append(y_true, labels.numpy())\n",
        "\n",
        "      images = images.view(-1,3,depth,height,width)\n",
        "\n",
        "      test = Variable(images.to(device), requires_grad=False)\n",
        "      labels = Variable(labels.to(device), requires_grad=False)\n",
        "\n",
        "      with torch.no_grad():\n",
        "      \n",
        "        # Forward propagation\n",
        "        outputs = model(test)\n",
        "        t_loss += error(outputs, labels)\n",
        "        \n",
        "        # Get predictions from the maximum value\n",
        "        predicted = torch.max(outputs.data, 1)[1]\n",
        "        #print(f\"prediction size are {predicted.shape}\")\n",
        "        y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
        "        # Total number of labels\n",
        "        total += len(labels)\n",
        "        correct += (predicted == labels).sum()\n",
        "  model.train()\n",
        "  loss = t_loss.cpu().numpy() / float(total)\n",
        "  test_loss.append(loss)\n",
        "  accuracy = 100 * correct / float(total)\n",
        "  test_acc.append(accuracy)\n",
        "\n",
        "  mcc_score = mcc(y_true, y_pred)\n",
        "  print(f\"MCC score is {round(mcc_score,4)}\")\n",
        "\n",
        "\n",
        "  global MCC_SCORE\n",
        "  if MCC_SCORE < mcc_score:\n",
        "      MCC_SCORE = mcc_score\n",
        "      os.makedirs(\"model_checkpoints\", exist_ok=True)\n",
        "      try:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'amp': amp.state_dict()    ##if amp is used\n",
        "            }, f\"model_checkpoints/3D_ptcl2stage2_resnext101_{epoch}for_cloud_size_32_64_64_acc_{round(accuracy.item(),3)}_mcc_{round(mcc_score.item(),3)}.pth\")\n",
        "        #torch.save(model.state_dict(), f\"model_checkpoints/3D_pointcloud_SimpleCNN_{epoch}for_cloud_size_32_64_64_acc_{round(accuracy.item(),3)}_mcc_{round(mcc_score.item(),3)}.pth\")\n",
        "      except:\n",
        "        pass\n",
        "  cf =confusion_matrix(y_true, y_pred)\n",
        "  #print(cf)\n",
        "  conf_mat(cf, epoch, accuracy, mcc_score, y_true, train_loss, train_acc, test_loss, test_acc)\n",
        "\n",
        "  print('TESTING ---> Epoch: {} Loss: {} Accuracy: {} %'.format(epoch, round(loss,3), round(accuracy.item(),3)))\n",
        "\n",
        "\n",
        "  return test_loss, test_acc\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ddJpxiHvjiu",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6KGqof_2dKH",
        "colab_type": "text"
      },
      "source": [
        "**TIP:** This training could take several hours depending on how many iterations you chose in the .cfg file. You will want to let this run as you sleep or go to work for the day, etc. However, Colab Cloud Service kicks you off it's VMs if you are idle for too long (30-90 mins).\n",
        "\n",
        "To avoid this hold (CTRL + SHIFT + i) at the same time to open up the inspector view on your browser.\n",
        "\n",
        "Paste the following code into your console window and hit **Enter**\n",
        "```\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document\n",
        "  .querySelector('#top-toolbar > colab-connect-button')\n",
        "  .shadowRoot.querySelector('#connect')\n",
        "  .click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVyBYPn3lHmd",
        "colab_type": "text"
      },
      "source": [
        "### Augmentation Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1JkIye18KEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment(images, labels, augment_volume=2):\n",
        "\n",
        "  [instances, channel, depth, height, width] = images.shape\n",
        "\n",
        "  images_aug = torch.zeros((instances*augment_volume, channel, depth, height, width))\n",
        "  labels_aug = torch.zeros(instances*augment_volume)\n",
        "\n",
        "  for aug_type in range(augment_volume):\n",
        "    augmented = im_aug(images, aug_type)\n",
        "    \n",
        "    images_aug[aug_type*instances:(aug_type+1)*instances, :, :, :, :] = augmented\n",
        "    labels_aug[aug_type*instances:(aug_type+1)*instances] = labels\n",
        "\n",
        "  return images_aug.float(), labels_aug.long()\n",
        "\n",
        "\n",
        "\n",
        "def im_aug(images, aug_type):\n",
        "\n",
        "    if aug_type == 0:\n",
        "      return images\n",
        "\n",
        "    elif aug_type == 1:\n",
        "      return torch.rot90(images, 1, [3,4])\n",
        "\n",
        "    elif aug_type == 2:\n",
        "      return torch.rot90(images, 2, [3,4])\n",
        "\n",
        "    elif aug_type == 3:\n",
        "      return torch.rot90(images, 3, [3,4])\n",
        "\n",
        "    elif aug_type == 4:\n",
        "      temp = torch.flip(images, [2,3])\n",
        "      return temp\n",
        "\n",
        "    elif aug_type == 5:\n",
        "      temp = torch.flip(images, [2,3])\n",
        "      return torch.rot90(temp, 1, [3,4])\n",
        "\n",
        "    elif aug_type == 6:\n",
        "      temp = torch.flip(images, [2,3])\n",
        "      return torch.rot90(temp, 2, [3,4])\n",
        "\n",
        "    elif aug_type == 7:\n",
        "      temp = torch.flip(images, [2,3])\n",
        "      return torch.rot90(temp, 3, [3,4])\n",
        "\n",
        "    elif aug_type == 8:\n",
        "      temp = torch.transpose(images, 3, 4)\n",
        "      return temp\n",
        "\n",
        "    elif aug_type == 9:\n",
        "      temp = torch.transpose(images, 3, 4)\n",
        "      return torch.rot90(temp, 1, [3,4])\n",
        "\n",
        "    elif aug_type == 10:\n",
        "      temp = torch.transpose(images, 3, 4)\n",
        "      return torch.rot90(temp, 2, [3,4])\n",
        "\n",
        "    elif aug_type == 11:\n",
        "      temp = torch.transpose(images, 3, 4)\n",
        "      return torch.rot90(temp, 3, [3,4])\n",
        "\n",
        "    elif aug_type == 12:\n",
        "      temp = torch.flip(images, [2,3])\n",
        "      temp = torch.transpose(temp, 3, 4)\n",
        "      return temp\n",
        "\n",
        "    elif aug_type == 13:\n",
        "      temp = torch.flip(images, [2,3])\n",
        "      temp = torch.transpose(temp, 3, 4)\n",
        "      return torch.rot90(temp, 1, [3,4])\n",
        "\n",
        "    elif aug_type == 14:\n",
        "      temp = torch.flip(images, [2,3])\n",
        "      temp = torch.transpose(temp, 3, 4)\n",
        "      return torch.rot90(temp, 2, [3,4])\n",
        "\n",
        "    elif aug_type == 15:\n",
        "      temp = torch.flip(images, [2,3])\n",
        "      temp = torch.transpose(temp, 3, 4)\n",
        "      return torch.rot90(temp, 3, [3,4])\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac5dOXwdlK5W",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRbHWrT1C5Ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "bf7b68ff-aaf3-42ba-df0d-1abece36ba22"
      },
      "source": [
        "### TRAINING code\n",
        "\n",
        "MCC_SCORE = 0\n",
        "\n",
        "\n",
        "train_loss = []   #to keep track of loss with respect to number of epoch \n",
        "test_loss = []\n",
        "iteration_list = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    #count = 1\n",
        "    accuracy_list = []\n",
        "    loss_list = []\n",
        "    for i, (images, labels) in tqdm(enumerate(train_dataloader_vox)):\n",
        "        correct = 0\n",
        "        \n",
        "        if augmentation_enabled == True:\n",
        "          images, labels = augment(images, labels, augment_volume)\n",
        "\n",
        "        images = images.view(-1,3,depth,height,width)\n",
        "\n",
        "        train_img = Variable(images.to(device), requires_grad=True)\n",
        "        labels = Variable(labels.to(device), requires_grad=False)\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward propagation\n",
        "        outputs = model(train_img)\n",
        "        # Calculate softmax and ross entropy loss\n",
        "        loss = error(outputs, labels)\n",
        "        \n",
        "        #labels = labels.view(-1, 1)  #only for BCELogitsloss\n",
        "        #loss = error(outputs.float(), labels.float())  #if BCELoss is measured\n",
        "        \n",
        "        # Calculating gradients\n",
        "        if use_amp:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "        #loss.backward()\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        predicted = torch.max(outputs.data, 1)[1]   \n",
        "        correct = (predicted == labels).sum()\n",
        "        total = len(labels)        \n",
        "        accuracy = 100 * correct / float(total)\n",
        "\n",
        "        '''\n",
        "        ###For BCELoss\n",
        "        predicted = torch.tensor([0 if i<=0.5 else 1 for i in outputs]).to(device)\n",
        "        accuracy = 100 * (predicted.detach() == labels).cpu().numpy().mean()\n",
        "        '''\n",
        "\n",
        "        accuracy_list = np.append(accuracy_list, accuracy.cpu().numpy())\n",
        "        loss_list = np.append(loss_list, loss.detach().cpu().numpy())\n",
        "        #print(f\"Training Mini Batch--> Epoch:{epoch} Iteration:{count} Loss :{loss} Accuracy: {accuracy}\")\n",
        "        #count += 1\n",
        "    final_loss = np.mean(loss_list)\n",
        "    final_acc = np.mean(accuracy_list)\n",
        "    print(f\"TRAINING ---> Epoch: {epoch} Loss: {round(final_loss,4)} Accuracy: {round(final_acc,4)}\")\n",
        "    train_loss.append(final_loss)\n",
        "    train_acc.append(final_acc)\n",
        "    gc.collect() \n",
        "    test_loss , test_acc = validation(epoch, train_loss, train_acc, test_loss, test_acc)\n",
        "    \n",
        "    if IS_FIRST_STAGE:\n",
        "      train_dataset_vox = VoxelDataset(\n",
        "        dataset_path=dataset_path,\n",
        "        split_path=split_path,\n",
        "        split_number=split_number,\n",
        "        training=True,\n",
        "      )\n",
        "      train_dataloader_vox = DataLoader(train_dataset_vox, batch_size= batch_size,sampler=BalancedBatchSampler(train_dataset_vox),shuffle=False, num_workers=4)\n",
        "    # else:\n",
        "    #   train_dataloader_vox = DataLoader(train_dataset_vox, batch_size= batch_size,shuffle=True, num_workers=4)\n",
        "    "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]\n",
            "0it [00:00, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "\n",
            "1it [00:28, 28.24s/it]\u001b[A\n",
            "2it [00:48, 25.92s/it]\u001b[A\n",
            "3it [01:09, 24.38s/it]\u001b[A\n",
            "4it [01:30, 23.24s/it]\u001b[A\n",
            "5it [01:50, 22.42s/it]\u001b[A\n",
            "6it [02:11, 21.85s/it]\u001b[A\n",
            "7it [02:31, 21.48s/it]\u001b[A\n",
            "8it [02:52, 21.21s/it]\u001b[A\n",
            "9it [03:12, 21.02s/it]\u001b[A\n",
            "10it [03:33, 20.88s/it]\u001b[A\n",
            "11it [03:54, 20.79s/it]\u001b[A\n",
            "12it [04:14, 20.72s/it]\u001b[A\n",
            "13it [04:35, 20.69s/it]\u001b[A\n",
            "14it [04:55, 20.65s/it]\u001b[A\n",
            "15it [05:16, 20.62s/it]\u001b[A\n",
            "16it [05:36, 20.60s/it]\u001b[A\n",
            "17it [05:57, 20.60s/it]\u001b[A\n",
            "18it [06:18, 20.59s/it]\u001b[A\n",
            "19it [06:38, 20.58s/it]\u001b[A\n",
            "20it [06:59, 20.57s/it]\u001b[A\n",
            "21it [07:17, 20.85s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAINING ---> Epoch: 0 Loss: 0.4495 Accuracy: 85.7853\n",
            "MCC score is 0.5513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|         | 1/50 [07:48<6:22:54, 468.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TESTING ---> Epoch: 0 Loss: 0.006 Accuracy: 81.697 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:23, 23.08s/it]\u001b[A\n",
            "2it [00:43, 22.41s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d0a85b3600ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# should_skip will always be False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mshould_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdelay_overflow_check\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_skip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mupdate_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If the fused kernel is available, we only need one D2H memcopy and sync.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLossScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fused_kernel\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overflow_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbFB8mHlzMND",
        "colab_type": "text"
      },
      "source": [
        "# Testing Validation Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WignzgdEctqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_aug(augment_enabled=False, augment_volume=16):\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  t_loss = 0\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for images, labels in test_dataloader_vox:\n",
        "\n",
        "      y_true = np.append(y_true, labels.numpy())\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        image_s = images.view(-1,3,depth,height,width)\n",
        "        test = Variable(image_s.to(device), requires_grad=False)\n",
        "        labels = Variable(labels.to(device), requires_grad=False)\n",
        "\n",
        "        # Forward propagation\n",
        "        outputs = model(test)\n",
        "\n",
        "        if (augment_enabled == True):\n",
        "\n",
        "            for aug_type in range(1, augment_volume):\n",
        "\n",
        "              image_s = im_aug(images, aug_type)\n",
        "              image_s = image_s.view(-1,3,depth,height,width)\n",
        "              test = Variable(image_s.to(device), requires_grad=False)\n",
        "              outputs = outputs + model(test)\n",
        "\n",
        "            outputs = outputs / augment_volume\n",
        "\n",
        "        t_loss += error(outputs, labels)\n",
        "        \n",
        "        # Get predictions from the maximum value\n",
        "        predicted = torch.max(outputs.data, 1)[1]\n",
        "        #print(f\"prediction size are {predicted.shape}\")\n",
        "        y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
        "        # Total number of labels\n",
        "        total += len(labels)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "\n",
        "  model.train()\n",
        "  loss = t_loss.cpu().numpy() / float(total)\n",
        "  accuracy = 100 * correct / float(total)\n",
        "\n",
        "  mcc_score = mcc(y_true, y_pred)\n",
        "  print(f\"MCC score is {round(mcc_score,4)}\")\n",
        "\n",
        "  print('TESTING ---> Loss: {} Accuracy: {} %'.format(round(loss,3), round(accuracy.item(),3)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLxXTtNs43qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_aug(augment_enabled=False, augment_volume=augment_volume) \n",
        "validation_aug(augment_enabled=True, augment_volume=4) \n",
        "validation_aug(augment_enabled=True, augment_volume=8) \n",
        "validation_aug(augment_enabled=True, augment_volume=16) \n",
        "\n",
        "print(\"Done\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}